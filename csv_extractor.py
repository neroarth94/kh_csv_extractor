#
# CSV aggregator script
# Consolidates the CSV files generated by Penlite+ software in to a single CSV file
#
# -> python csv_aggregator.py -f <csv file folder> -o <output.csv>
#

import re
import sys
from optparse import OptionParser
from pathlib import Path
import csv
import os
import glob


test_configs = [ 
                # Test Name     Rows to skip
                ('INTERCON',                3 ),
                ('PULL_DOWN',               3 ),
                ('LEAKAGE',                 3 ),
                ('TSR',                     3 ),
                #('UID_CRC_CHECK',           3 ),
                #('ID_BITS_DECODE',          3 ),
                #('PEN_CRC_VERIFY',          3 ),
                #('MROM_CHECK',              3 ),
                #('ID_BITS_READ',            3 )
                ('RSCAN',                   1 ),
                #('RSCANSTATISTICS',         1 ),
                #('RSCANSTATISTICS_LIMIT',   1 ),
               ]



def process_files(csv_folder, output_csv_file):

    # Create the CSV writter object
    write_file = open(output_csv_file, 'w', newline='')
    csv_writter = csv.writer(write_file, delimiter=',')
    csv_writter.writerow(["Pen ID", "Test", "Signal Name", "Value", "LSL", "USL", "State"])
    print(output_csv_file)

    # Get list of CSV files to process
    csv_folder_path = Path(csv_folder)
    if not csv_folder_path.is_dir():
        print(f"EXITING !!! {csv_folder} doesn't exists")
        return

    os.chdir(csv_folder)
    files = glob.glob("*.csv")

    # Check if the output file exists
    '''
    file_path = Path(output_csv_file)
    if file_path.is_file():
        print("Exiting !!! Output file alreday exists")
        return
    '''

    # Iterate through all the CSV files and search for test results
    for file in files:
        print(f"[INFO] Processing file : {file}")
        penid = get_penid(file)

        for test_config in test_configs:
            test_data, test_result = parse_test_results(file, test_config[0])
            
            if not test_data:
                continue

            for row in test_data:
                #print([penid, test_config[0].strip(':')] + row)
                csv_writter.writerow([penid, test_config[0]] + row)



def get_penid(file):
    ''' Returns the Pen ID from the given CSV file. Returns None if not found '''
    # Open the CSV file
    with open (file, newline='') as csvfile:
        # Get Pen ID
        for line in csvfile:
            if line.startswith("Pen ID:"):
                tmp = line.split()
                print(f"[INFO] Pen Id = {tmp[2]}")
                return tmp[2]
    
    return None

def parse_test_results(file, test_name):
    ''' Returns test data '''
    rows = []
    test_result = "NA"

    with open(file, newline='') as csvfile:
        csv_reader = csv.reader(csvfile, delimiter=',')
        for row in csv_reader:
            print(test_name)
            if len(row) > 0 and row[0].startswith(test_name+":"):
            # if len(row) > 0 and row[0].startswith(test_name+":"):
                test_result = row[0].split(':')[1]
                print(f"[INFO] Found test data for {test_name} result {test_result}")
                # Skip the rows that are not relevant
                
                for test_config in test_configs:
                    if test_config[0] == test_name:
                        for i in range(test_config[1]):
                            next(csv_reader)

                for row in csv_reader:
                    if len(row) == 0:
                        return rows, test_result
                    rows.append(row)
    return rows, test_result


if __name__ == "__main__":
    # Command line options parser
    usage_str = "usage: %prog [options]"
    parser = OptionParser(usage=usage_str)
    parser.add_option("-f", "--folder", dest="csv_folder", metavar="FILE", help="Specifies input CSV folder")
    parser.add_option("-o", "--output", dest="output_csv_file", metavar="FILE", help="Output CSV file")
    (options, args) = parser.parse_args(sys.argv)

    print(f"Starting CSV aggregator. CSV folder = {options.csv_folder}, Output file = {options.output_csv_file}")
    process_files(options.csv_folder, options.output_csv_file)
    


